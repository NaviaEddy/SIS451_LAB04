{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from fastprogress import master_bar, progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cargar_dataset(ruta_dataset, tamaño_imagen=(50, 50)):\n",
        "    # Reiniciar variables\n",
        "    dataset = []\n",
        "    etiquetas_mapping = {}\n",
        "\n",
        "    # Obtener clases del nuevo dataset y ordenarlas\n",
        "    clases = sorted(os.listdir(ruta_dataset))\n",
        "\n",
        "    # Mapeo de etiquetas a valores numéricos\n",
        "    etiquetas_mapping = {clase: idx for idx, clase in enumerate(clases)}\n",
        "\n",
        "    for clase in clases:\n",
        "        #print(f\"Procesando clase testing: {clase} ({etiquetas_mapping[clase]})\")\n",
        "        ruta_clase = os.path.join(ruta_dataset, clase)\n",
        "        etiqueta_num = etiquetas_mapping[clase]  # Obtener el valor numérico de la etiqueta directamente\n",
        "        with os.scandir(ruta_clase) as entries:\n",
        "            for idx, entry in enumerate(entries, start=1):\n",
        "                if entry.is_file():\n",
        "                    imagen_ruta = os.path.join(ruta_clase, entry.name)\n",
        "                    # Abrir imagen como objeto PIL\n",
        "                    imagen = Image.open(imagen_ruta).convert('RGB')\n",
        "                    # Normalizar la imagen\n",
        "                    imagen = np.array(imagen) / 255.0\n",
        "                    # Convertir la imagen normalizada a objeto PIL\n",
        "                    imagen_pil = Image.fromarray((imagen * 255).astype(np.uint8))\n",
        "                    # Redimensionar imagen\n",
        "                    imagen_resized = imagen_pil.resize(tamaño_imagen)\n",
        "                    dataset.append((imagen_resized, etiqueta_num))  # Tupla con imagen y etiqueta numérica\n",
        "\n",
        "    random.shuffle(dataset)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = (\"Afghan hound\", \"Beagle\", \"Bulldog Ingles\", \"Collie\", \"Coocker\", \"German Pointer\", \"Golden retriever\", \"Malamutes\", \"Pug\", \n",
        "           \"Saint bernard\", \"Schnauzer\", \"Siberian Husky\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset = cargar_dataset('completados final\\completados')\n",
        "\n",
        "print(\"Número de ejemplos en el conjunto de entrenamiento:\", len(trainset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9heVm3uIRvQG",
        "outputId": "6c99f29f-989a-4f57-e59e-ef63e9d99679"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, trainset):\n",
        "    self.imgs = torch.tensor([np.array(i[0]).flatten() / 255. for i in trainset], dtype=torch.float, device=device)\n",
        "    self.labels = torch.tensor([i[1] for i in trainset], dtype=torch.long, device=device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    return self.imgs[ix], self.labels[ix]\n",
        "\n",
        "train = Dataset(trainset)\n",
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXL4baRiRvQJ",
        "outputId": "c28dca42-2345-48d8-dcc7-535df46b9692"
      },
      "outputs": [],
      "source": [
        "img, label = train[10]\n",
        "img.shape, img.dtype, img.max(), img.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vytYRgyRvQM",
        "outputId": "1eef7063-4748-45d3-d7f2-0922c4f23381"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
        "\n",
        "imgs, labels = next(iter(dataloader))\n",
        "imgs.shape, labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "54wKrLkyRvQQ",
        "outputId": "7845e6f2-32b1-4539-8d32-53bb82c5959f"
      },
      "outputs": [],
      "source": [
        "r, c = 3, 5\n",
        "plt.figure(figsize=(c*3, r*3))\n",
        "for row in range(r):\n",
        "    for col in range(c):\n",
        "        index = c*row + col\n",
        "        plt.subplot(r, c, index + 1)\n",
        "        ix = random.randint(0, len(train)-1)\n",
        "        img, label = train[ix]\n",
        "        # Aquí asumo que img es de tamaño 50x50x3\n",
        "        plt.imshow(img.reshape(50, 50, 3).cpu())\n",
        "        plt.axis('off')\n",
        "        plt.title(classes[label.item()])\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Yyw-LMTRvQU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def block(n_in, n_out):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(n_in, n_out),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.fc1 = block(input_size, 150)\n",
        "    self.fc2 = block(150, 100)\n",
        "    self.fc3 = nn.Linear(100, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnHPFDyBRvQX"
      },
      "outputs": [],
      "source": [
        "n_in, n_out = 30, 50*50*3\n",
        "generator = MLP(n_in, n_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3lEt25FRvQa",
        "outputId": "226cf055-ae89-4328-dbed-dea81714b8e0"
      },
      "outputs": [],
      "source": [
        "output = generator(torch.randn(64, 30))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGtKK3S5RvQc"
      },
      "source": [
        "Obviamente, nuestro generador inicializado genera imágenes aleatorias que en nada se parecen a las reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "nW5ZAzgERvQd",
        "outputId": "fd6aa4a2-330e-44fe-ed89-0b02535b1e20"
      },
      "outputs": [],
      "source": [
        "plt.imshow(output[0].reshape(50,50,3).detach().numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDqr5-f9RvQh"
      },
      "source": [
        "El discriminador, por otro lado, recibirá a la entrada una imagen (28 x 28 valores) y a la salida nos dará una clasificación binaria (real o falso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0taWml7YRvQi",
        "outputId": "a3b0c523-67eb-4616-ba05-ac9e7548de7f"
      },
      "outputs": [],
      "source": [
        "discriminator = MLP(50*50*3, 1)\n",
        "output = discriminator(torch.randn(64, 50*50*3))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L67YhLqRvQk"
      },
      "source": [
        "La siguiente función será la responsable de entrenar ambas redes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ieCzFATRvQl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def fit(g, d, dataloader, epochs=30, crit=None):\n",
        "  g.to(device)\n",
        "  d.to(device)\n",
        "  g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "  d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "  crit = nn.BCEWithLogitsLoss() if crit == None else crit\n",
        "  g_loss, d_loss = [], []\n",
        "  mb = master_bar(range(1, epochs+1))\n",
        "  hist = {'g_loss': [], 'd_loss': []}\n",
        "  for epoch in mb:\n",
        "\n",
        "    for X, y in progress_bar(dataloader, parent=mb):\n",
        "      # X, y = X.to(device), y.to(device)\n",
        "      # entrenamos el discriminador\n",
        "      g.eval()\n",
        "      d.train()\n",
        "      #   generamos un batch de imágenes falsas\n",
        "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "      genenerated_images = g(noise)\n",
        "      #   input del discrminator\n",
        "      d_input = torch.cat([genenerated_images, X.view(X.size(0), -1)])\n",
        "      #   gorund truth para el discriminator\n",
        "      d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1,1).to(device)\n",
        "      #   optimización\n",
        "      d_optimizer.zero_grad()\n",
        "      d_output = d(d_input)\n",
        "      d_l = crit(d_output, d_gt)\n",
        "      d_l.backward()\n",
        "      d_optimizer.step()\n",
        "      d_loss.append(d_l.item())\n",
        "      # entrenamos el generador\n",
        "      g.train()\n",
        "      d.eval()\n",
        "      #   generamos un batch de imágenes falsas\n",
        "      noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "      genenerated_images = g(noise)\n",
        "      #   salidas del discriminador\n",
        "      d_output = d(genenerated_images)\n",
        "      #   gorund truth para el generator\n",
        "      g_gt = torch.ones(X.size(0)).view(-1,1).to(device)\n",
        "      #   optimización\n",
        "      g_optimizer.zero_grad()\n",
        "      g_l = crit(d_output, g_gt)\n",
        "      g_l.backward()\n",
        "      g_optimizer.step()\n",
        "      g_loss.append(g_l.item())\n",
        "      # logs\n",
        "      mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "    mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "    hist['g_loss'].append(np.mean(g_loss))\n",
        "    hist['d_loss'].append(np.mean(d_loss))\n",
        "  return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "tLbSqzbqRvQn",
        "outputId": "8f1873fc-f08a-4b7d-f9e5-6667c27a9b01"
      },
      "outputs": [],
      "source": [
        "hist = fit(generator, discriminator, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "5Pz4zXKFRvQq",
        "outputId": "330ee151-be31-49a3-fb3c-f170cc8b0037"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df = pd.DataFrame(hist)\n",
        "df.plot(grid=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "IUABTSLSRvQt",
        "outputId": "141ec4b0-c0a3-4cbc-e01f-68c669062ad0"
      },
      "outputs": [],
      "source": [
        "generator.eval()\n",
        "with torch.no_grad():\n",
        "  noise = torch.randn((10, generator.input_size)).to(device)\n",
        "  generated_images = generator(noise)\n",
        "  fig, axs = plt.subplots(2,5,figsize=(15,5))\n",
        "  i = 0\n",
        "  for ax in axs:\n",
        "    for _ax in ax:\n",
        "      img = generated_images[i].view(50, 50, 3).cpu()\n",
        "      _ax.imshow(img)\n",
        "      i+=1\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z__XIyQHRvQy"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 100\n",
        "        self.inp = nn.Sequential(\n",
        "            nn.Linear(self.input_size, 256*25*25),  # Ajustamos para que coincida con las dimensiones requeridas para generar una imagen de 50x50\n",
        "            nn.BatchNorm1d(256*25*25),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 3, 4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inp(x)\n",
        "        x = x.view(-1, 256, 25, 25)  # Ajustamos para que coincida con las dimensiones requeridas para generar una imagen de 50x50\n",
        "        x = self.main(x)\n",
        "        x = x.view(x.size(0), 3*50*50)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p39Ezo1NRvQ1",
        "outputId": "de4e2c53-8878-499e-f23b-88825796b587"
      },
      "outputs": [],
      "source": [
        "\n",
        "generator = Generator()\n",
        "output = generator(torch.randn(64, 100))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEtvDyiURvQ3"
      },
      "source": [
        "Al final del generador usamos una activación `tanh`, que dará valores entre -1 y 1. Por este motivo tenemos que re-normalizar nuestras imágenes en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqxVv-DaRvQ4",
        "outputId": "62469a6a-7a10-4c36-d2b6-87a6630bb5d1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, trainset):\n",
        "    self.imgs = torch.tensor([np.array(i[0]).flatten() / 255. for i in trainset], dtype=torch.float, device=device)\n",
        "    self.imgs = self.imgs * 2. - 1.\n",
        "    self.labels = torch.tensor([i[1] for i in trainset], dtype=torch.long, device=device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    return self.imgs[ix], self.labels[ix]\n",
        "\n",
        "train = Dataset(trainset)\n",
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKcWAEKmRvQ6",
        "outputId": "0d395522-2535-4c1e-8043-46028c08e6bf"
      },
      "outputs": [],
      "source": [
        "img, label = train[0]\n",
        "img.shape, img.dtype, img.max(), img.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0926xTdFRvQ8",
        "outputId": "cf126336-70bf-4684-d65e-1fff5ca7eebb"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
        "\n",
        "imgs, labels = next(iter(dataloader))\n",
        "imgs.shape, labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jS594hJRvRA"
      },
      "source": [
        "En cuanto al discriminador, utilizaremos una `CNN` típica como las que conocemos cuando hacemos clasificación de imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3BsrEAARvRB"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Conv2d(3, 256, 4, stride=2, padding=1, bias=False),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.out = nn.Sequential(\n",
        "        nn.Linear(256*25*25, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # esperamos vectores a la entrada de 28*28\n",
        "    x = x.view(x.size(0), 3, 50, 50)\n",
        "    x = self.main(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.out(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pegKxb5RvRD",
        "outputId": "c1c09ec3-affb-46c6-ce14-579d0569f7da"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()\n",
        "output = discriminator(torch.randn(64, 3,50,50))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqXmPfu1RvRG"
      },
      "source": [
        "Ahora podemos utilizar exactamente el mismo bucle de entrenamiento anterior para obtener un nuevo generador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "-tOMYAqQRvRG",
        "outputId": "71d33685-1bdc-4979-a713-c6e555baae0f"
      },
      "outputs": [],
      "source": [
        "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "XIFnctljRvRJ",
        "outputId": "0054307a-2e60-4bc7-ab34-131d9cd59d47"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(hist)\n",
        "df.plot(grid=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "F273gfyMRvRL",
        "outputId": "cb71af7c-3da2-4867-e08f-fa45627e8bfb"
      },
      "outputs": [],
      "source": [
        "generator.eval()\n",
        "with torch.no_grad():\n",
        "  noise = torch.randn((10, generator.input_size)).to(device)\n",
        "  generated_images = generator(noise)\n",
        "  fig, axs = plt.subplots(2,5,figsize=(15,5))\n",
        "  i = 0\n",
        "  for ax in axs:\n",
        "    for _ax in ax:\n",
        "      img = generated_images[i].view(3, 50,50).cpu()\n",
        "      _ax.imshow(img)\n",
        "      i+=1\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YJF45MWVBgd"
      },
      "source": [
        "En este caso las imágenes generadas son un poco mejores que las que obteníamos con la *GAN* simple, aunque todavía hay márgen de mejora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMbrXYsvuh44"
      },
      "source": [
        "> ⚡¿Te ves capaz de utilizar este código como base para entrenar una *GAN* capaz de generar caras realistas? Para ello puedes utilizar el dataset [CelebA](https://pytorch.org/docs/stable/torchvision/datasets.html#celeba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ivkeoquh44"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "En este post hemos aprendido a implementar *GANs*, redes neuronales capaces de generar datos similares a los usados en el entrenamiento, en este caso imágenes. Este tipo de arquitecturas están formadas por dos redes neuronales que compiten entre sí durante el entrenamiento: el generador y el discriminador. El generador se encarga de generar imágenes falsas a partir de un vector de valores aleatorios, que se puede interpretar como una versión comprimida de la imagen, mientras que el discriminador se encarga de distinguir entre imágenes reales, obtenidas del dataset, y falsas, generadas por el generador. Una vez entrenado el modelo, descartamos el discriminador y nos quedamos con el generador que será capaz de generar imágenes realistas, similares a la usadas en el dataset. Este tipo de modelos se utilizan para generar caras de gente que no existe, colorear imágenes en blanco y negro, generar imágenes realistas a partir de máscaras de segmentación, incluso los famosos *deep fakes*."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
